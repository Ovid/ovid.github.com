[%
    title            = 'AI-Generated Content: Innovation or Intellectual Theft?';
    type             = 'articles';
    slug             = 'ai-generated-content-innovation-or-intellectual-theft';
    include_comments = 1;
    syntax_highlight = 1;
    date             = '2024-09-11';
    mathjax          = 0;
    # facebook         = 'babylon.jpg'; # 1,200 x 628 pixels recommended, but can be smaller
    # facebook_alt     = 'A cuneiform tablet with Babylonian numbers inscribed on it.';
    USE Ovid;
%]
[% WRAPPER include/wrapper.tt blogdown=1 -%]

{{TOC}}
{{TAGS ai}}

# Introduction

It's no exaggeration to say that we're worried [we might lose our jobs to
AI](/articles/will-you-lose-your-job-to-ai.html). The value of human language
translation outside of specialized contexts[% Ovid.note("Legal, medical,
fiction, etc.") %] is effectively zero. Call center workers have, for years,
been replaced with AI systems, systems which are getting even better.
Copywriters and journalists are seeing generative AI encroach on their work.

And the ability of generative AI relentlessly advances, though not with the
same growth in ability we saw in the early days. Many of the advances are
subtle, but powerful. The latest version of ChatGPT, released as a preview a few
days ago, shows some amazing abilities to plan.

Now [Billie Eilish, Nicki Minaj, Stevie Wonder, and others call for protecting
their jobs against
AI](https://www.theguardian.com/technology/2024/apr/02/musicians-demand-protection-against-ai).

## Jobs versus Progress

Do you remember the public outcry when the availability of cheap alarm clocks
put knocker-uppers out of work? No? You don't even know what
[knocker-uppers](https://en.wikipedia.org/wiki/Knocker-up) are?

OK, what about when electric lights put lamp-lighters out of work? What about
agricultural workers, switchboard operators, ice cutters, toll booth collectors,
or, or, or ...

There was no outcry. Those were jobs for poor people. Often immigrants. Nobody
cared. "Progress!" was the rallying cry. But when famous artists call for
protecting their jobs against AI, _now_ there's public outcry. Can't have the
rich and famous getting hurt, can we?

Of course, there have been a few outcries before, such as when Luddites were
losing their jobs. [I've written briefly about them
before](/blog/marc-andreessen-techno-babble.html#luddites), but this is the
exception, not the rule.

So there's more than a whiff of hypocrisy here. It's OK for poor, unknown people
to suffer, but not rich, famous people.

Or, to give those complaining the benefit of the doubt, maybe they didn't care
that "Progress!" ruins the jobs of poor people because eventually they'll find
new jobs, but when technology can take _everyone's_ jobs, that's where the fear
comes in?

But that's a bit of an extreme position, too, because AI is clearly not going to
take everyone's jobs; I'm not going to a robot barber any time soon. Currently
we're seeing labor market transformation, not collapse. Some jobs are being lost
while others are being created.

But really, it comes down to one thing: the _scale_ of the change we may be
facing. Before we get to that, let's talk about the electronic elephant in the
room, AGI.

## Artificial General Intelligence (AGI)

Definitions of AGI vary because we can't define "intelligence," but the
definitions revolve around when AI might be able to solve all or most
intellectual challenges at or above the level that humans can. But for the sake
of argument, we'll just say AGI means "equal to an average human."

So let's consider the rumor that [OpenAI is considering charging $2,000 a
month for their next generation
model](https://www.pymnts.com/artificial-intelligence-2/2024/report-openai-considers-2000-monthly-subscription-prices-for-new-llms/).
We have no idea if those rumors are true, but it sounds insane, doesn't it? I
pay twenty bucks a month for ChatGPT. Why would I want to pay one hundred times
that amount?

If we hit AGI at some point, $2K/month is a steal and businesses will be
scrambling to pay it. Why? That's $24K a year. In 2022, [the average annual US
salary was about $64K](https://www.ssa.gov/oact/cola/AWI.html). So if we have
AGI and it can replace you, one AGI is about a third the cost of the average
American.

Oh, but it's even cheaper than that! AI doesn't sleep. It can work a 24 hours a
day, seven days a week. So the cost of the AI is an order of magnitude cheaper
than your average American. And they don't complain. They don't stop. They don't
go to HR. They don't join unions. They don't require health insurance.

If AGI is achieved, what's a business going to do? Their direct and indirect
labor costs are an order of magnitude cheaper, and many of their continent costs
_go away_. No more wrongful termination suits. No workman's comp claims. No
severance pay. No compliance costs. Unless there is significant legislation
coming down the pike to stop this, any business which can adopt AI but chooses
not to is going to be remembered fondly as naïve idealists who went bankrupt.

## The Current State of AI

But are we there yet? [OpenAI's next model, Strawberry, allegedly is supposed to
be incredibly
powerful](https://www.pymnts.com/artificial-intelligence-2/2024/report-openai-considers-2000-monthly-subscription-prices-for-new-llms/).

> Strawberry will be able to solve problems and tasks that are beyond the
capabilities of current AI models. It will be able to solve math problems it has
never encountered; perform high-level tasks like developing market strategies
and solving complex word puzzles; and perform “deep research.”

We're not done there! [Strawberry is rumored to be used in training _Orion_,
OpenAI's model after Strawberry, and the successor to ChatGPT
4o](https://the-decoder.com/openais-strawberry-ai-is-reportedly-the-secret-sauce-behind-next-gen-orion-language-model/).

For those not working regularly with AI, it's hard to understand the impact of
our current foundation models, but they're already transforming many businesses.
If Orion-class models have a similar upgrade in capability—something we can't
possibly know until they're released—all bets are off. If I had to
guess, I think Orion _won't_ be AGI, but we might be bumping up against it. I am
not willing to wager large sums of money on my guess.

## The Legal Landscape

OK, that's some background. What about the creators who don't want to go the way
of the knocker-upper and lose their jobs to AI? There are numerous lawsuits
against companies training models on artist's works, but it's unclear what will
happen.

What _is_ clear is copyright law: [I have every right to copy your style, so
long as I don't copy your content, or pass my work off as your
own](https://www.trails.umd.edu/news/ai-imitating-artist-style-drives-call-to-rethink-copyright-law).
I can paint like you, I can sing like you, I can write like you. (Well, I can't,
but you get the point).

It's a critical concept because ideas can't be copyrighted. Imagine all of the
lawsuits suing writers of books because similar plotlines have been used (boy
meets girl, girl hates boy, she changes her mind), and then you, like the
original author, used an unusual second-person POV. It would be madness.

How could I copy your style? By reading your writing. By viewing your artwork.
By hearing your songs. That's what much of generative AI is doing. Somehow, what
you and I are allowed to do—see things and imitate them—generative AI is not
allowed to do.

So it's not clear that artists can claim copyright protection for AI-generated
output. In fact, since anyone can produce great art, whether images or songs,
via AI, the Copyright Office would be overwhelmed by trying to process all of
those requests. We're simply not set up to handle this.

Initially, the US Copyright office denied copyrights for all AI-generated work.
That seems odds because I'm allowed to copyright art created with a guitar, a
brush, or Photoshop, but not Midjourney? Well, [the Copyright Office started
relaxing its opposition last
year](https://www.theartnewspaper.com/2023/05/04/us-copyright-office-artificial-intelligence-art-regulation),
so long as there's substantial human creativity involved in the process.

But yeah. What does that mean? On its face, the artists probably aren't going to
win on the grounds of copyright violations, [though there are many pending court
cases surrounding
this](https://www.bakerlaw.com/services/artificial-intelligence-ai/case-tracker-artificial-intelligence-copyrights-and-class-actions/).

The arguments seem to largely fall into two categories. The most prevalent is
that various companies are "illegally" scraping copyrighted content to train
their models. Well, how do I learn something? I look at it. I study it. I'm
allowed, but the AI is not? That seems a curious dichotomy.

On the other hand, if the content explicitly _forbids_ such scraping, then yes,
I can see the plaintiffs prevailing—if they can prove that their content was
scraped.

But there's another curious angle. Many cases are arguing that [defendants have
made _copies_ of copyrighted work for training their
models](https://www.ropesgray.com/en/insights/alerts/2024/04/ai-and-the-copyright-liability-overhang-a-brief-summary-of-the-current-state-of-ai-related).
In fact, you should probably read through that entire link to get an idea as to
the scope of these lawsuits. If it can be successfully argued that defendants
are illegally storing lossy, compressed versions of copyrighted works in the
weights of models, maybe there's a case? Though it's worth pointing out that
you keep lossy, compressed versions of copyrighted work in your brain. Carbon
good, silicon bad? That being said, humans do so at a much smaller scale than
AI.

I know, it _sounds_ like I'm defending AI at all costs, but I'm not. Bear with
me; I'm trying to be fair.  People I talk to about this tend to come down on one
side or another, reflecting their personal views, regardless of the merits of a
given case. Of course, we tend to do this about many court cases, facts be
damned.

Despite not being a lawyer, or having anything resembling a law degree, I'm
willing to bet that the AI companies will largely prevail on these issues,
despite losing on some points. I say that because I went to university to be an
economist (came out a software developer) and I know what often happens when
large sums of money meet murky legal terrain: money wins.

## Legislating AI

So the law needs to change, but how?

Let me put it this way: any legal change you suggest is going to have
wide-ranging consequences, not all of them good. For example, famed Perl hacker
Randal Schwartz, [was convicted of a felony for doing what he thought was his
job](https://www.theregister.com/2007/03/05/intel_hacker_charges_quashed/).

At the time of the initial case, [Oregon law, title 16, chapter 164
read](https://web.archive.org/web/20050204184944/http://www.lightlink.com/spacenka/fors/164-377.txt):

> Any person who knowingly and without authorization uses, accesses
or attempts to access any computer, computer system, computer network, or
any computer software, program, documentation or data contained in such
computer, computer system or computer network, commits computer crime [is guilty
of a class C felony].

You could, in theory, be guilty of a felony for leaving a voicemail for someone
who told you not to call them. Or maybe a family member shared their Netflix
password with you. That's a felony! Or you use a VPN that allows you to read US
websites from outside the US. That's a felony!

That law [has since been
amended](https://oregon.public.law/statutes/ors_164.377). It was
well-intentioned, but the larger the scope of a law, the more possibilities it
can be abused.

Remember Prohibition? Though well-intentioned, [it almost single-handedly
created organized crime in the
US](https://prohibition.themobmuseum.org/the-history/the-rise-of-organized-crime/the-mob-during-prohibition/).[%
Ovid.note("If you argue that it was not well-intended, I argue that you need to
read a history book or three on the topic. I think it was a bad law from the
start, but one of the many reasons it was proposed was to protect women being
abused by drunken husbands. Turns out that women were abused even more during
Prohibition.") %]

Remember the Smoot-Hawley Tariff Act of 1930? That was passed during the Great
Depression, raising tariffs to protect US agriculture. Due to the retaliatory
tariffs, [this law was blamed for worsening the Great Depression
worldwide](https://www.investopedia.com/terms/s/smoot-hawley-tariff-act.asp).

Remember the various three-strikes laws? [One man was sentenced to life in
prison for shoplifting a pair of white socks worth
$2.50](https://www.rollingstone.com/politics/politics-news/cruel-and-unusual-punishment-the-shame-of-three-strikes-laws-92042/).
Others received life sentences for stealing food. But the law was
well-intentioned.

# Conclusion

So where does this leave us? We're standing at the precipice of a technological
revolution that could make the Industrial Revolution look like a warm-up act.
AI may be coming for our jobs and it's not just the assembly line workers or
the telephone operators this time—it's gunning for the artists, the writers,
the coders, and [maybe even the
CEOs](https://www.cnbc.com/2023/09/19/nearly-half-of-ceos-believe-ai-could-replace-their-own-jobs-poll.html).

Is it hypocritical for famous artists to cry foul now when we've collectively
shrugged at decades of technological job displacement? Perhaps. But maybe their
star power is exactly what we need to finally have a serious conversation about
the broader implications of AI on our workforce.

The legal battleground is murkier than a swamp in fog, with copyright laws
struggling to keep pace with silicon's relentless march. Some are calling for AI
companies to pay licensing fees for the copyrighted material they use to train
their models, similar to how streaming services pay royalties to artists.  Sound
fair? Plot twist: Such a move could inadvertently raise the barriers to entry in
the AI field. We might end up with a greater market consolidation, with only the
tech giants able to afford the licensing fees. Is trading artist exploitation
for tech monopolies really a step forward? Or are we just rearranging deck
chairs on the Titanic of our economy?

One thing's for certain: the AI train has left the station, and it's picking up
speed. We can either scramble to lay down tracks in front of it, or we can
start thinking about redesigning our entire transportation system.

The real question isn't whether AI will take our jobs—it's what we're going to
do if it does. Will we finally address the fundamental issues of wealth
distribution and the value of human labor? Or will we continue to bury our
heads in the silicon sand until even that job is automated?

The future's coming, folks, whether we like it or not. The choice is ours:
adapt, evolve, or become as obsolete as a knocker-upper in a world of alarm
clocks. Welcome to the brave new world—hope you brought your resume.

[%- END %]
